{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "from sklearn.datasets import make_circles\n",
    "import torch\n",
    "\n",
    "#1000 samples\n",
    "n_samples = 1000\n",
    "\n",
    "#create circle\n",
    "x, y = make_circles(n_samples, noise=0.03, random_state=42)\n",
    "\n",
    "print(f\"First 5 samples of X : \\n {x[:5]}\")\n",
    "print(f\"First 5 samples of Y : \\n {y[:5]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Make dataframe of circle data\n",
    "import pandas as pd\n",
    "\n",
    "circles = pd.DataFrame({\"X1\": x[:, 0],\n",
    "                        \"X2\": x[:, 1],\n",
    "                        \"labels\": y})\n",
    "circles.head(10)"
   ],
   "id": "ef9ae33d4687164e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#visualize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x=x[:, 0], y=x[:, 1], c=y, cmap=plt.cm.RdYlBu)\n"
   ],
   "id": "3b9ff37c7ce01463",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check input output shapes",
   "id": "82ab62b4d3b321ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x.shape, y.shape",
   "id": "a57ffd8b1e07514c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#View feature and labels\n",
    "x_sample = x[0]\n",
    "y_sample = y[0]\n",
    "\n",
    "#data into tensors\n",
    "x = torch.from_numpy(x).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "x[:5], y[:5]"
   ],
   "id": "f9076422843f7ea3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "#split into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "len(x_train), len(x_test), len(y_train), len(y_test)"
   ],
   "id": "1072af0e19d405ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#building model\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class CircleModelv0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=2, out_features=5)\n",
    "        self.layer2 = nn.Linear(in_features=5, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer2(self.layer1(x))  #x->layer1->layer2->output\n",
    "\n",
    "\n",
    "model1 = CircleModelv0().to(device)\n",
    "model1.state_dict()"
   ],
   "id": "4ae6c5ed8c6cf217",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "next(model1.parameters())\n",
    "model1.state_dict()\n"
   ],
   "id": "41fa78bac0f2d74c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#using sequential\n",
    "\n",
    "model1 = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=5),\n",
    "    nn.Linear(in_features=5, out_features=1),\n",
    ").to(device)\n",
    "\n",
    "model1.state_dict()"
   ],
   "id": "dfd913fc386f1c1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.inference_mode():\n",
    "    untrained_pred = model1(x_test.to(device))\n",
    "print(f\"Length of prediction: {len(untrained_pred)}, Shape: {untrained_pred.shape}\")\n",
    "print(f\"Length of test sample: {len(x_test)}, Shape: {x_test.shape}\")\n",
    "print(f\"\\nFirst 10 prediction: {untrained_pred[:10]}\")\n",
    "print(f\"\\nFirst 10 label: {y_test[:10]}\")"
   ],
   "id": "9458db31688eff2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(params=model1.parameters(), lr=0.1)"
   ],
   "id": "bd2dc5e6ca5e5a1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#calculate accuracy\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n"
   ],
   "id": "c6711e545c81f7ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Train Model\n",
    "#raw logits -> prediction probabilities -> predictiom labels\n",
    "\n",
    "model1.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model1(x_test.to(device))[:5]\n",
    "print(y_logits)"
   ],
   "id": "d9fb92d02e451339",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#logits turn into prediction probabilities\n",
    "\n",
    "y_pred_probs = torch.sigmoid(y_logits)\n",
    "print(y_pred_probs)"
   ],
   "id": "a0405243986c5653",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#find prediction labels\n",
    "y_pred = torch.round(y_pred_probs)\n",
    "y_pred_label = torch.round(torch.sigmoid(model1(x_test.to(device))[:5]))\n",
    "print(torch.eq(y_pred.squeeze(), y_pred_label.squeeze()))\n",
    "y_pred.squeeze()"
   ],
   "id": "dd709d9b2b9a14a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.cuda.manual_seed(42)\n",
    "epochs = 100\n",
    "x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model1.train()\n",
    "\n",
    "    y_logits = model1(x_train.to(device)).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "    #    loss = loss_fn(torch.sigmoid(y_logits), y_pred)\n",
    "\n",
    "    loss = loss_fn(y_logits, y_train)\n",
    "    acc = accuracy_fn(y_true=y_train, y_pred=y_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model1(x_test.to(device)).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test, y_pred=test_pred)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss:.5f}, Accuracy: {acc:.2f}, Test accuracy: {test_acc:.2f}\")"
   ],
   "id": "6e43436c39c90351",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#prediction vialise\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "    print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "    print(\"Downloading helper_functions.py\")\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "    with open(\"helper_functions.py\", \"wb\") as f:\n",
    "        f.write(request.content)\n"
   ],
   "id": "60c64db7311a4b49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helper_functions import plot_predictions, plot_decision_boundary\n",
    "\n",
    "#plot descsion boudnary of a model\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Train')\n",
    "plot_decision_boundary(model1, x_train, y_train)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Test')\n",
    "plot_decision_boundary(model1, x_test, y_test)"
   ],
   "id": "df056b62e8330572",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imporving\n",
   "id": "6f2474e214fa2a51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CircleModelV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=10)\n",
    "        self.layer_2 = nn.Linear(in_features=10, out_features=10)  # extra layer\n",
    "        self.layer_3 = nn.Linear(in_features=10, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_3(self.layer_2(self.layer_1(x)))\n",
    "\n",
    "\n",
    "model_1 = CircleModelV1().to(device)\n",
    "model_1"
   ],
   "id": "711f89df53b625c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()  # Does not require sigmoid on input\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr=0.1)"
   ],
   "id": "6f3451cee67efedc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 1000  # Train for longer\n",
    "\n",
    "# Put data to target device\n",
    "x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    # 1. Forward pass\n",
    "    y_logits = model_1(x_train).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))  # logits -> prediction probabilities -> prediction labels\n",
    "\n",
    "    # 2. Calculate loss/accuracy\n",
    "    loss = loss_fn(y_logits, y_train)\n",
    "    acc = accuracy_fn(y_true=y_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_1(x_test).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        test_loss = loss_fn(test_logits,\n",
    "                            y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
   ],
   "id": "a1cc62de7fd9da8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Train')\n",
    "plot_decision_boundary(model1, x_train, y_train)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Test')\n",
    "plot_decision_boundary(model1, x_test, y_test)"
   ],
   "id": "d3437ce5cbfc0498",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#trying this model on straight line\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.01\n",
    "\n",
    "x_regression = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y_regression = weight * x_regression + bias\n"
   ],
   "id": "aae6c470bca85b06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_split = int(0.8 * len(x_regression))\n",
    "x_train_regression, y_train_regression = x_regression[:train_split], y_regression[:train_split]\n",
    "x_test_regression, y_test_regression = x_regression[train_split:], y_regression[train_split:]"
   ],
   "id": "6edeefc31379d99f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_predictions(train_data=x_train_regression,\n",
    "                 train_labels=y_train_regression,\n",
    "                 test_data=x_test_regression,\n",
    "                 test_labels=y_test_regression\n",
    "                 );"
   ],
   "id": "f9c061e79b758b8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model2 = nn.Sequential(\n",
    "    nn.Linear(in_features=1, out_features=10),\n",
    "    nn.Linear(in_features=10, out_features=10),\n",
    "    nn.Linear(in_features=10, out_features=1)\n",
    ").to(device)\n",
    "model2"
   ],
   "id": "f39f39b94a1a65b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=0.1)"
   ],
   "id": "a683e870cd2483d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 1400\n",
    "\n",
    "# Put data to target device\n",
    "x_train_regression, y_train_regression = x_train_regression.to(device), y_train_regression.to(device)\n",
    "x_test_regression, y_test_regression = x_test_regression.to(device), y_test_regression.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    # 1. Forward pass\n",
    "    y_pred = model2(x_train_regression)\n",
    "\n",
    "    # 2. Calculate loss (no accuracy since it's a regression problem, not classification)\n",
    "    loss = loss_fn(y_pred, y_train_regression)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model2.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_pred = model2(x_test_regression)\n",
    "        # 2. Calculate the loss\n",
    "        test_loss = loss_fn(test_pred, y_test_regression)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Train loss: {loss:.5f}, Test loss: {test_loss:.5f}\")"
   ],
   "id": "b87b704c38590f34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Turn on evaluation mode\n",
    "model2.eval()\n",
    "\n",
    "# Make predictions (inference)\n",
    "with torch.inference_mode():\n",
    "    y_preds = model2(x_test_regression)\n",
    "\n",
    "# Plot data and predictions with data on the CPU (matplotlib can't handle data on the GPU)\n",
    "# (try removing .cpu() from one of the below and see what happens)\n",
    "plot_predictions(train_data=x_train_regression.cpu(),\n",
    "                 train_labels=y_train_regression.cpu(),\n",
    "                 test_data=x_test_regression.cpu(),\n",
    "                 test_labels=y_test_regression.cpu(),\n",
    "                 predictions=y_preds.cpu());"
   ],
   "id": "4c20bbd184b3d1eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "X, y = make_circles(n_samples=1000,\n",
    "                    noise=0.03,\n",
    "                    random_state=42,\n",
    "                    )\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu);"
   ],
   "id": "79526d1fb2fb07c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Turn data into tensors\n",
    "X = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42\n",
    "                                                    )\n",
    "\n",
    "X_train[:5], y_train[:5]"
   ],
   "id": "851abb46cbe357d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class CircleModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=10)\n",
    "        self.layer_2 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.layer_3 = nn.Linear(in_features=10, out_features=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n",
    "\n",
    "model_3 = CircleModelV2().to(device)\n",
    "print(model_3)"
   ],
   "id": "834d9e58fcb3b39c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model_3.parameters(), lr=0.1)"
   ],
   "id": "b0e3f2d1108d167a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "epochs = 1100\n",
    "\n",
    "# Put all data on target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 1. Forward pass\n",
    "    y_logits = model_3(X_train).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))  # logits -> prediction probabilities -> prediction labels\n",
    "\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = loss_fn(y_logits, y_train)  # BCEWithLogitsLoss calculates loss using logits\n",
    "    acc = accuracy_fn(y_true=y_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_3.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_logits = model_3(X_test).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))  # logits -> prediction probabilities -> prediction labels\n",
    "        # 2. Calculate loss and accuracy\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")"
   ],
   "id": "33a51ff46d41a7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot decision boundaries for training and test sets\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train\")\n",
    "plot_decision_boundary(model_1, X_train, y_train)  # model_1 = no non-linearity\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Test\")\n",
    "plot_decision_boundary(model_3, X_test, y_test)  # model_3 = has non-linearity"
   ],
   "id": "d93ce62f29547c82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Multiclass classification\n",
   "id": "1de13242bbbf9dcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#hyperparameters\n",
    "num_class = 4\n",
    "num_features = 2\n",
    "random_seed = 42\n",
    "\n",
    "#create multiclass data\n",
    "x_blob, y_blob = make_blobs(n_samples=1000, n_features=num_features, random_state=random_seed, centers=num_class,\n",
    "                            cluster_std=1.5)\n",
    "\n",
    "# data into tensor\n",
    "x_blob, y_blob = (torch.from_numpy(x_blob).type(torch.float),\n",
    "                  torch.from_numpy(y_blob).type(torch.LongTensor))\n",
    "\n",
    "#split into training and test\n",
    "x_blob_train, x_blob_test, y_blob_train, y_blob_test = train_test_split(x_blob, y_blob, test_size=0.2,\n",
    "                                                                        random_state=random_seed)\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.scatter(x_blob[:, 0], x_blob[:, 1], c=y_blob, cmap=plt.cm.RdYlBu)"
   ],
   "id": "4e2936420180b796",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "62fec9b03ec52822",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BlobModel(nn.Module):\n",
    "    def __init__(self, input_features, output_features, hidden_features=8):\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_features, out_features=hidden_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_features, out_features=output_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x)\n",
    "\n",
    "\n",
    "model4 = BlobModel(input_features=2, output_features=4, hidden_features=8).to(device)\n",
    "model4"
   ],
   "id": "6b846f9a906256a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model4.parameters(),\n",
    "                            lr=0.1)"
   ],
   "id": "d5f73bbb75bd0cac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(model4(x_blob_train.to(device))[0].shape, num_class)\n",
    "print(model4(x_blob_train.to(device))[:5])"
   ],
   "id": "c47e42dc7ee83262",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make prediction logits with model\n",
    "y_logits = model4(x_blob_test.to(device))\n",
    "\n",
    "# Perform softmax calculation on logits across dimension 1 to get prediction probabilities\n",
    "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "print(y_logits[:5])\n",
    "print(y_pred_probs[:5])"
   ],
   "id": "ba9a1d7ea7822f14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fit the model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 15\n",
    "\n",
    "# Put data to target device\n",
    "X_blob_train, y_blob_train = x_blob_train.to(device), y_blob_train.to(device)\n",
    "X_blob_test, y_blob_test = x_blob_test.to(device), y_blob_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model4.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_logits = model4(X_blob_train)  # model outputs raw logits\n",
    "    y_pred = torch.softmax(y_logits, dim=1).argmax(\n",
    "        dim=1)\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = loss_fn(y_logits, y_blob_train)\n",
    "    acc = accuracy_fn(y_true=y_blob_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model4.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_logits = model4(X_blob_test)\n",
    "        test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "        # 2. Calculate test loss and accuracy\n",
    "        test_loss = loss_fn(test_logits, y_blob_test)\n",
    "        test_acc = accuracy_fn(y_true=y_blob_test,\n",
    "                               y_pred=test_pred)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\n",
    "            f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}%\")"
   ],
   "id": "bb1b2017f449e865",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make predictions\n",
    "model4.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model4(X_blob_test)\n",
    "\n",
    "# View the first 10 predictions\n",
    "print(y_logits[:10])"
   ],
   "id": "ea66b05bcd840368",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "print(y_pred_probs[:10])"
   ],
   "id": "8e119f0e0edff9c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train\")\n",
    "plot_decision_boundary(model4, X_blob_train, y_blob_train)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Test\")\n",
    "plot_decision_boundary(model4, X_blob_test, y_blob_test)"
   ],
   "id": "2fcedfe5ba8fc114",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install torchmetrics",
   "id": "a77cfa1c0ef60aa3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchmetrics import Accuracy\n",
    "# Setup metric and make sure it's on the target device\n",
    "torchmetrics_accuracy = Accuracy(task='multiclass', num_classes=4).to(device)\n",
    "\n",
    "# Calculate accuracy\n",
    "torchmetrics_accuracy(y_pred_probs, y_blob_test)"
   ],
   "id": "9ac9c1e38129805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "91fb8a308ea40512",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
