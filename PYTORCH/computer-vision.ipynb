{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup training data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,  # get test data\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ],
   "id": "1191f3f7eb6a567a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)\n",
    "class_names = train_data.classes\n",
    "class_names"
   ],
   "id": "85ab58f8efbfb903",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image, label = train_data[2323]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze())  # image shape is [1, 28, 28] (colour channels, height, width)\n",
    "plt.title(label);"
   ],
   "id": "a79a24eae0153a2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False);"
   ],
   "id": "f4207cd2fb5a5f47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True\n",
    "                              )\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False\n",
    "                             )\n",
    "\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ],
   "id": "174419b47704c1dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ],
   "id": "e69dae7a1ec0b184",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model 0: Build a baseline model",
   "id": "44992357a4848c17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flatten_model = nn.Flatten()  # all nn modules function as a model (can do a forward pass)\n",
    "\n",
    "x = train_features_batch[0]\n",
    "\n",
    "output = flatten_model(x)  # perform forward pass\n",
    "\n",
    "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")"
   ],
   "id": "de369063ef206d6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class model0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_shape, hidden_units),\n",
    "            nn.Linear(hidden_units, output_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ],
   "id": "87797f72f1e00a62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_0 = model0(input_shape=784,  # one for every pixel (28x28)\n",
    "                 hidden_units=10,  # how many units in the hidden layer\n",
    "                 output_shape=len(class_names)  # one for every class\n",
    "                 )\n",
    "model_0.to(\"cpu\")"
   ],
   "id": "7967845600535683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_0.parameters(), lr=0.1)"
   ],
   "id": "2fab915cff4cb976",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Training time on {device} \", total_time, \"seconds\")\n",
    "    return total_time"
   ],
   "id": "2962e037b96f2dda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "epoch = 3\n",
    "\n",
    "for epoch in tqdm(range(epoch)):\n",
    "    print(epoch)\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        y_pred = model_0(x)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(x)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for x, y in test_dataloader:\n",
    "            test_pred = model_0(x)\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc = test_acc / len(test_dataloader)\n",
    "        print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(model_0.parameters()).device))"
   ],
   "id": "1271101684e9340a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#make prediction\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def eval_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module, accuracy_fn):\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for x, y in data_loader:\n",
    "            y_pred = model(x)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    return {\"model_name\": model.__class__.__name__,\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "\n",
    "model_0_result = eval_model(model_0, test_dataloader, loss_fn, accuracy_fn)\n",
    "model_0_result"
   ],
   "id": "5c0c3242560b081b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup device agnostic code\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "id": "41ed6f63d3beff6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Building a better model with non-linearity",
   "id": "2c89c38889ae2ef3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class model1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_shape, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, output_shape),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ],
   "id": "fbf2459ffa4b278",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = model1(input_shape=784, hidden_units=10, output_shape=len(class_names))\n",
    "device = torch.device(\"cuda\")  # Force CUDA\n",
    "model_1.to(device)  # Move model to GPU\n",
    "print(\"Model 1 is on:\", next(model_1.parameters()).device, model_1.parameters())"
   ],
   "id": "7f71fc151cc1178d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
    "                            lr=0.1)"
   ],
   "id": "3f1556c6d4da1b63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1))  # Go from logits -> pred labels\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                                    y_pred=test_pred.argmax(dim=1)  # Go from logits -> pred labels\n",
    "                                    )\n",
    "\n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ],
   "id": "89cf11750658e6da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader,\n",
    "               model=model_1,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn\n",
    "               )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "              model=model_1,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn\n",
    "              )\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=device)"
   ],
   "id": "cf3b332117532e2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for x, y in data_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    return {\"model_name\": model.__class__.__name__, \"model_loss\": loss.item(), \"model_acc\": acc}\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_1.to(device)\n",
    "\n",
    "model_1_result = eval_model(model=model_1, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn,\n",
    "                            device=device)\n",
    "model_1_result"
   ],
   "id": "8f3958ef8f26f67f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_0_result",
   "id": "962d90fa14775e7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Building a Convolutional Neural Network (CNN)",
   "id": "fef5c13ffe31d08e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CNN1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_units * 7 * 7, output_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "CNN_1 = CNN1(input_shape=1, hidden_units=10, output_shape=len(class_names)).to(device)\n",
    "CNN_1"
   ],
   "id": "5ac459be3eb2a904",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create sample batch of random numbers with same size as image batch\n",
    "images = torch.randn(size=(32, 3, 64, 64))  # [batch_size, color_channels, height, width]\n",
    "test_image = images[0]  # get a single image for testing\n",
    "print(f\"Image batch shape: {images.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Single image shape: {test_image.shape} -> [color_channels, height, width]\")\n",
    "#dimenstion of both image are different due to batch number\n",
    "print(f\"Single image pixel values:\\n{test_image}\")"
   ],
   "id": "549a40a7c45ae5f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10,\n",
    "                       kernel_size=3,\n",
    "                       stride=1,\n",
    "                       padding=0)\n",
    "conv_layer(test_image)"
   ],
   "id": "a71bf497d577844e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#matching dimention of batch image and test image for later purpose\n",
    "print(test_image.unsqueeze(dim=0).shape)\n",
    "conv_layer(test_image.unsqueeze(dim=0)).shape"
   ],
   "id": "67c379c594e4b7d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "conv_layer_2 = nn.Conv2d(in_channels=3,  # same number of color channels as our input image\n",
    "                         out_channels=10,\n",
    "                         kernel_size=(5, 5),  # kernel is usually a square so a tuple also works\n",
    "                         stride=2,\n",
    "                         padding=0)\n",
    "conv_layer_2(test_image.unsqueeze(dim=0)).shape"
   ],
   "id": "6056a7ad8447691c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(conv_layer_2.state_dict())",
   "id": "7d3eeeafa6a00da7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get shapes of weight and bias tensors within conv_layer_2\n",
    "print(\n",
    "    f\"conv_layer_2 weight shape: \\n{conv_layer_2.weight.shape} -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\")\n",
    "print(f\"\\nconv_layer_2 bias shape: \\n{conv_layer_2.bias.shape} -> [out_channels=10]\")"
   ],
   "id": "d1c712b04ebb8c8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Test image original shape: {test_image.shape}\")\n",
    "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(dim=0).shape}\")\n",
    "\n",
    "# Create a sample nn.MaxPoo2d() layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# Pass data through just the conv_layer\n",
    "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
    "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
    "\n",
    "# Pass data through the max pool layer\n",
    "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
    "print(f\"Shape after going through conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")"
   ],
   "id": "c05febd00384f1da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=CNN_1.parameters(),\n",
    "                            lr=0.1)"
   ],
   "id": "4e99e7c4d5ab6067",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "from timeit import Timer\n",
    "\n",
    "train_time_start_cnn1 = timer()\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch {epoch}\\n\")\n",
    "train_step(data_loader=train_dataloader, model=CNN_1, loss_fn=loss_fn,\n",
    "           optimizer=optimizer, accuracy_fn=accuracy_fn, device=device)\n",
    "test_step(data_loader=test_dataloader, model=CNN_1, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "train_time_end_cnn1 = timer()\n",
    "total_train_time_cnn1 = print_train_time(start=train_time_start_cnn1, end=train_time_end_cnn1, device=device)"
   ],
   "id": "44444e271d8d5e49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cnn1_result = eval_model(model=CNN_1,data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn)\n",
    "cnn1_result"
   ],
   "id": "6db8a3bd4f21c848",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "compare_results = pd.DataFrame([model_0_result, model_1_result, cnn1_result] )\n",
    "compare_results"
   ],
   "id": "6e59a854c26bab85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
    "                                    total_train_time_model_1,\n",
    "                                    total_train_time_cnn1]\n",
    "compare_results"
   ],
   "id": "b07c4b8fd4571c9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize our model results\n",
    "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
    "plt.xlabel(\"accuracy (%)\")\n",
    "plt.ylabel(\"model\");"
   ],
   "id": "509c05c1173b524e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            # Prepare sample\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device) # Add an extra dimension and send sample to device\n",
    "\n",
    "            # Forward pass (model outputs raw logit)\n",
    "            pred_logit = model(sample)\n",
    "\n",
    "            # Get prediction probability (logit -> prediction probability)\n",
    "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 1, so can perform on dim=0)\n",
    "\n",
    "            # Get pred_prob off GPU for further calculations\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "\n",
    "    # Stack the pred_probs to turn list into a tensor\n",
    "    return torch.stack(pred_probs)"
   ],
   "id": "e911bc034af48f33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "for sample, label in random.sample(list(test_data), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "print(\n",
    "    f\"Test sample image shape: {test_samples[0].shape}\\nTest sample label: {test_labels[0]} ({class_names[test_labels[0]]})\")"
   ],
   "id": "bd6efa293488478c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make predictions on test samples with model 2\n",
    "pred_probs= make_predictions(model=CNN_1,\n",
    "                             data=test_samples)\n",
    "\n",
    "# View first two prediction probabilities list\n",
    "pred_probs[:2]"
   ],
   "id": "b36b4bea81846279",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "pred_classes, test_labels, pred_classes\n"
   ],
   "id": "9262245bf7a82107",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(9, 9))\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "for i, sample in enumerate(test_samples):\n",
    "    # Create a subplot\n",
    "    plt.subplot(nrows, ncols, i + 1)\n",
    "\n",
    "    plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
    "\n",
    "    # Find the prediction label (in text form, e.g. \"Sandal\")\n",
    "    pred_label = class_names[pred_classes[i]]\n",
    "\n",
    "    # Get the truth label (in text form, e.g. \"T-shirt\")\n",
    "    truth_label = class_names[test_labels[i]]\n",
    "\n",
    "    title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
    "\n",
    "    if pred_label == truth_label:\n",
    "        plt.title(title_text, fontsize=10, c=\"g\")\n",
    "    else:\n",
    "        plt.title(title_text, fontsize=10, c=\"r\")\n",
    "    plt.axis(False);"
   ],
   "id": "a6c28c6bab0bc40a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Make predictions with trained model\n",
    "y_preds = []\n",
    "CNN_1.eval()\n",
    "with torch.inference_mode():\n",
    "  for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "    # Send data and targets to target device\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    # Do the forward pass\n",
    "    y_logit = CNN_1(X)\n",
    "    # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 32, so can perform on dim=1)\n",
    "    # Put predictions on CPU for evaluation\n",
    "    y_preds.append(y_pred.cpu())\n",
    "# Concatenate list of predictions into a tensor\n",
    "y_pred_tensor = torch.cat(y_preds)"
   ],
   "id": "1a0e82cc3cc7bc4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T04:08:00.525668Z",
     "start_time": "2025-04-14T04:07:43.047657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# 2. Setup confusion matrix instance and compare predictions to targets\n",
    "confmat = ConfusionMatrix(num_classes=len(class_names), task='multiclass')\n",
    "confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "                         target=test_data.targets)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy\n",
    "    class_names=class_names, # turn the row and column labels into class names\n",
    "    figsize=(10, 7)\n",
    ");"
   ],
   "id": "3690bbafa1936f92",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n",
      "D:\\Artificial\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmlxtend\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mplotting\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m plot_confusion_matrix\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m# 2. Setup confusion matrix instance and compare predictions to targets\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m confmat = ConfusionMatrix(num_classes=\u001B[38;5;28mlen\u001B[39m(\u001B[43mclass_names\u001B[49m), task=\u001B[33m'\u001B[39m\u001B[33mmulticlass\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      7\u001B[39m confmat_tensor = confmat(preds=y_pred_tensor,\n\u001B[32m      8\u001B[39m                          target=test_data.targets)\n\u001B[32m     10\u001B[39m \u001B[38;5;66;03m# 3. Plot the confusion matrix\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'class_names' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True,\n",
    "                 exist_ok=True )\n",
    "\n",
    "MODEL_NAME = \"CNN1\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=CNN_1.state_dict(),\n",
    "           f=MODEL_SAVE_PATH)"
   ],
   "id": "eefc83104005154",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loaded_model_2 = CNN1(input_shape=1,\n",
    "                                    hidden_units=10, # try changing this to 128 and seeing what happens\n",
    "                                    output_shape=10)\n",
    "\n",
    "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
    "\n",
    "loaded_model_2 = loaded_model_2.to(device)"
   ],
   "id": "5e4b963520108b27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "loaded_model_2_results = eval_model(\n",
    "    model=loaded_model_2,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn\n",
    ")\n",
    "\n",
    "loaded_model_2_results"
   ],
   "id": "2f382800769bf43a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fd6f3dc4e7e5b62c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
