{
 "cells": [
  {
   "cell_type": "code",
   "id": "eeb887424ab465ca",
   "metadata": {},
   "source": [
    "# import zipfile\n",
    "#\n",
    "# from fontTools.misc.cython import returns\n",
    "# !curl -O https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
    "#\n",
    "# zip_ref = zipfile.ZipFile('nlp_getting_started.zip')\n",
    "# zip_ref.extractall()\n",
    "# zip_ref.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"nlp_getting_started/train.csv\")\n",
    "test_df = pd.read_csv(\"nlp_getting_started/test.csv\")\n",
    "train_df.head()"
   ],
   "id": "dad9e84a549879dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)  # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ],
   "id": "e78f3090ec68e5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_df.target.value_counts()",
   "id": "d553f712cbae9abc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "random_index = random.randint(0, len(train_df) - 5)\n",
    "for row in train_df[[\"text\", \"target\"]][random_index:random_index + 5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"target: {target}\", \"(Real disaster)\" if target > 0 else \"(Not Real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"--------------\\n\")"
   ],
   "id": "3f9437bf023953b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Split data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1, random_state=42)"
   ],
   "id": "8045539fe3da7ec9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)",
   "id": "417727c49f6773fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_sentences[:5]",
   "id": "922d4a757c731c37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#converting text to number\n",
    "import tensorflow as tf\n",
    "from keras.api.layers import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=500000, standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\", ngrams=None, output_mode=\"int\",\n",
    "    output_sequence_length=None, pad_to_max_tokens=True,\n",
    ")\n"
   ],
   "id": "118ee2a021cafda4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(train_sentences[0].split())",
   "id": "5d9bbc0394b99147",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "round(sum([len(i.split()) for i in train_sentences])) / len(train_sentences)",
   "id": "bfd8f998f4912c9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_vocab_length = 10000\n",
    "max_length = 15\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_length,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")\n",
    "text_vectorizer.adapt(train_sentences)"
   ],
   "id": "36409c52e4a28333",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_sentences = \"There's a flood in my street !!\"\n",
    "text_vectorizer([sample_sentences])"
   ],
   "id": "afc17af8e0cc6e0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Choose a random sentence frm dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original sentence: \\n {random_sentence}\\\n",
    "      \\n\\nVectorize version:\")\n",
    "text_vectorizer([random_sentence])"
   ],
   "id": "edd66a2934fd2775",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:]\n",
    "print(f\"Number of word in vocabulary: {len(words_in_vocab)}\")\n",
    "print(f\"5 most common word: {top_5_words}\")\n",
    "print(f\"5 least common word: {bottom_5_words}\")"
   ],
   "id": "533692d369c5be72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Creating an Embedding using an Embedding layer\n",
    "from keras.api.layers import Embedding\n",
    "embeddings=Embedding(input_dim=max_vocab_length,\n",
    "                     output_dim=128,\n",
    "                     embeddings_initializer=\"uniform\",\n",
    "                     input_length=max_length, name=\"embeddings_1\")\n",
    "embeddings"
   ],
   "id": "9946e78801c5a905",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original sentence: \\n {random_sentence}\\\n",
    "\\n\\nVectorize version:\")\n",
    "\n",
    "sample_embeded=embeddings(text_vectorizer([random_sentence]))\n",
    "sample_embeded"
   ],
   "id": "eb33e7bbff37fcdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sample_embeded[0][0],sample_embeded[0][0].shape, random_sentence",
   "id": "3dba13a86798b161",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#model 0\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), #convert words into numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()) #model the text\n",
    "])\n",
    "\n",
    "model0.fit(train_sentences, train_labels)"
   ],
   "id": "1a1e08a64ce2876c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "baseline_score=model0.score(val_sentences, val_labels)\n",
    "print(f\"Baseline score: {baseline_score*100:.2f}%\")"
   ],
   "id": "f4059bdb800e865a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "baseline_preds=model0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ],
   "id": "a2ef9e3e2a99921f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_labels[:20]",
   "id": "226c464d7884cbf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_result(y_true, y_pred):\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    model_prediction, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_prediction,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1,\n",
    "    }\n",
    "    return model_results"
   ],
   "id": "768c30f74d7cb098",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "baseline_result=calculate_result(y_true=val_labels, y_pred=baseline_preds)\n",
    "baseline_result"
   ],
   "id": "a251705ade7039c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from FRAME.TENSORFLOW.helper_functions import create_tensorboard_callback\n",
    "\n",
    "SAVE_DIR= \"model_logs\""
   ],
   "id": "c7cf5a419a3ba770",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.api.layers import Input,Dense,GlobalAveragePooling1D\n",
    "from keras.api.models import Model\n",
    "inputs=Input(shape=(1,), dtype=tf.string)\n",
    "x=text_vectorizer(inputs)\n",
    "x=embeddings(x)\n",
    "x=GlobalAveragePooling1D()(x)\n",
    "outputs=Dense(1, activation=\"sigmoid\")(x)\n",
    "model1=Model(inputs=inputs, outputs=outputs, name=\"model1_dense\")"
   ],
   "id": "287392ab0fe517cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.api.optimizers import Adam\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "model1.summary()"
   ],
   "id": "d78f873448785597",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model1_history=model1.fit(train_sentences, train_labels, epochs=5, validation_data=(val_sentences, val_labels),\n",
    "                          callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,experiment_name=\"simple-dense-model\")],verbose=2)"
   ],
   "id": "803c4a2f4bc217cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model1.evaluate(val_sentences, val_labels)",
   "id": "aebb59a3f50858c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "embeddings.weights",
   "id": "e45920d0d2e4d6fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dd7c709260871be6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embed_weights=model1.get_layer(\"embeddings_1\").get_weights()[0]\n",
    "print(embed_weights.shape)"
   ],
   "id": "2c46611d32ea97ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "model_1_pred_probs=model1.predict(val_sentences)\n",
    "model_1_pred_probs[:10]"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model1_preds=tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model1_preds[:10]"
   ],
   "id": "7fe0ebd3725217d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model1_results=calculate_result(y_true=val_labels, y_pred=model1_preds)\n",
    "model1_results"
   ],
   "id": "b483a2a61795cbb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "np.array(list(model1_results.values()))>np.array(list(baseline_result.values()))"
   ],
   "id": "4eda5a2484bca981",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a helper function to compare our baseline results to new model results\n",
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_result,\n",
    "                                new_model_results=model1_results)"
   ],
   "id": "f1ac30e86f81fa12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "words_in_vocab=text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab),words_in_vocab[:10]"
   ],
   "id": "e6ea401f74fa8c79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model1.summary()",
   "id": "608a4a796a7179e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embed_weights=model1.get_layer(\"embeddings_1\").get_weights()[0]\n",
    "embed_weights.shape"
   ],
   "id": "6bce64fd643467dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import io\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embed_weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ],
   "id": "3e8449415c9f7913",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.api.layers import LSTM\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model_2_embedding = Embedding(input_dim=max_vocab_length, output_dim=128, embeddings_initializer=\"uniform\",\n",
    "                              input_length=max_length, name=\"embeddings_2\")\n",
    "\n",
    "input=Input(shape=(1,), dtype=\"string\")\n",
    "x=text_vectorizer(input)\n",
    "x=model_2_embedding(x)\n",
    "print(x.shape)\n",
    "\n",
    "x=LSTM(64)(x)\n",
    "print(x.shape)\n",
    "\n",
    "outputs=Dense(1, activation=\"sigmoid\")(x)\n",
    "model2=Model(input, outputs, name=\"model2_LSTM\")"
   ],
   "id": "5a97bd4cd111df55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model2.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])",
   "id": "5e3e5f4cd26c0352",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model2.summary()",
   "id": "4a3a6407299d43ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model2_history = model2.fit(train_sentences, train_labels, epochs=5, validation_data=(val_sentences, val_labels),\n",
    "                            callbacks=[create_tensorboard_callback(SAVE_DIR, \"LSTM\")], verbose=2)"
   ],
   "id": "77366f00bcacd95e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_2_pred_probs=model2.predict(val_sentences)\n",
    "model_2_pred_probs.shape,model_2_pred_probs[:10]"
   ],
   "id": "bf804359dbddcf49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ],
   "id": "ea8398f0160e4f98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_2_results = calculate_result(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ],
   "id": "b233796de8356cfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compare_baseline_to_new_results(baseline_result, model_2_results)",
   "id": "a9dfd18f7934e493",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.api.layers import GRU\n",
    "#Model GRU\n",
    "tf.random.set_seed(42)\n",
    "model_3_embedding = Embedding(input_dim=max_vocab_length, output_dim=128, embeddings_initializer=\"uniform\",\n",
    "                              input_length=max_length, name=\"embeddings_3\")\n",
    "input=Input(shape=(1,), dtype=\"string\")\n",
    "x=text_vectorizer(input)\n",
    "x=model_3_embedding(x)\n",
    "x=GRU(64)(x)\n",
    "outputs=Dense(1, activation=\"sigmoid\")(x)\n",
    "model3=Model(input, outputs, name=\"model3_GRU\")"
   ],
   "id": "3f1046e796774719",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model3.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])",
   "id": "4e5b476cd71bea65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model3.summary()",
   "id": "521be7dd7b3e3428",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model3_history = model3.fit(train_sentences, train_labels, epochs=5, validation_data=(val_sentences, val_labels),\n",
    "                            verbose=2)"
   ],
   "id": "45310a8c0acaf215",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model3_pred_probs=model3.predict(val_sentences)\n",
    "model3_pred_probs.shape,model3_pred_probs[:10]"
   ],
   "id": "925b2e99b212701",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model3_preds = tf.squeeze(tf.round(model3_pred_probs))\n",
    "model3_preds[:10]"
   ],
   "id": "35e0e7ec2dd33709",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model3_results = calculate_result(y_true=val_labels, y_pred=model3_preds)\n",
    "model3_results"
   ],
   "id": "3e359728683ca746",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compare_baseline_to_new_results(baseline_result, model3_results)",
   "id": "cdcfeee7c3293f60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#bidirectional RNN model\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "from keras.api.layers import Bidirectional\n",
    "\n",
    "model4_embedding = Embedding(input_dim=max_vocab_length, output_dim=128, embeddings_initializer=\"uniform\",\n",
    "                             input_length=max_length, name=\"embeddings_4\")\n",
    "input=Input(shape=(1,), dtype=\"string\")\n",
    "x=text_vectorizer(input)\n",
    "x=model4_embedding(x)\n",
    "x=Bidirectional(LSTM(64))(x)\n",
    "outputs=Dense(1, activation=\"sigmoid\")(x)\n",
    "model4=Model(input, outputs, name=\"model4_bidirectional\")"
   ],
   "id": "54aa169101291117",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model4.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "model4.summary()"
   ],
   "id": "5ab52a9c01cb6091",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model4_history = model4.fit(train_sentences, train_labels, epochs=5, validation_data=(val_sentences, val_labels),\n",
    "                            verbose=2)"
   ],
   "id": "c70b07474688d4da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model4_pred_probs=model4.predict(val_sentences)\n",
    "model4_pred_probs.shape,model4_pred_probs[:10]"
   ],
   "id": "a16baff1812890f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model4_preds = tf.squeeze(tf.round(model4_pred_probs))\n",
    "model4_preds[:10]"
   ],
   "id": "c3070951d3b07298",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model4_results = calculate_result(y_true=val_labels, y_pred=model4_preds)\n",
    "model4_results"
   ],
   "id": "f4648f4bccc73b65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compare_baseline_to_new_results(baseline_result, model4_results)",
   "id": "eafd8d95d5c9d34a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using CNN for TEXT",
   "id": "b381efe57392853b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.api.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "embedding_test = embeddings(text_vectorizer([\"this is a test sentence\"]))\n",
    "conv_1d = Conv1D(filters=32, kernel_size=5, activation=\"relu\")\n",
    "conv_1d_output = conv_1d(embedding_test)\n",
    "max_pool = GlobalMaxPooling1D()\n",
    "max_pool_output = max_pool(conv_1d_output)\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ],
   "id": "1563e4c795609c95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]",
   "id": "be59dbfcec64b8fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tf.random.set_seed(42)\n",
    "model5_embedding = Embedding(input_dim=max_vocab_length, output_dim=128, embeddings_initializer=\"uniform\",input_length=max_length, name=\"embeddings_5\")\n",
    "input=Input(shape=(1,), dtype=\"string\")\n",
    "x=text_vectorizer(input)\n",
    "x=model5_embedding(x)\n",
    "x=Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x=GlobalAveragePooling1D()(x)\n",
    "outputs=Dense(1, activation=\"sigmoid\")(x)\n",
    "model5=Model(input, outputs, name=\"model5\")\n",
    "model5.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "model5.summary()"
   ],
   "id": "c33aeff05ff5b173",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model5_history = model5.fit(train_sentences, train_labels, epochs=5, validation_data=(val_sentences, val_labels),\n",
    "                            verbose=2)"
   ],
   "id": "fa0c866e66b925d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model5_pred_probs=model5.predict(val_sentences)\n",
    "model5_pred_probs[:10]"
   ],
   "id": "90f3efb747e5b54c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert model_5 prediction probabilities to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model5_pred_probs))\n",
    "model_5_preds[:10]"
   ],
   "id": "a0ba4b1f2ef9c52c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_5_results = calculate_result(y_true=val_labels, y_pred=model_5_preds)\n",
    "model_5_results"
   ],
   "id": "3dbb0458f6e90e45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compare_baseline_to_new_results(baseline_result, model_5_results)",
   "id": "eb59a270a371a47b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_model_results = pd.DataFrame({\n",
    "    \"baseline\": baseline_result,\n",
    "    \"model1\": model1_results,\n",
    "    \"model2\": model_2_results,\n",
    "    \"model3\": model3_results,\n",
    "    \"model4\": model4_results,\n",
    "    \"model5\": model_5_results\n",
    "})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ],
   "id": "6967f068e7f139f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T13:38:05.259412Z",
     "start_time": "2025-04-23T13:38:02.066684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"uciml/german-credit\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "id": "43b20d2966d7df26",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Artificial\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/uciml/german-credit?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10.9k/10.9k [00:00<00:00, 3.82MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\anmol\\.cache\\kagglehub\\datasets\\uciml\\german-credit\\versions\\1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
