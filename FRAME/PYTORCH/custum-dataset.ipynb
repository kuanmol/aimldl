{
 "cells": [
  {
   "cell_type": "code",
   "id": "1972dee26187a676",
   "metadata": {},
   "source": "import torch",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "9132c64680d5261c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} exists\")\n",
    "else:\n",
    "    print(f\"{image_path} does not exist\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        requests = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(requests.content)\n",
    "\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\")\n",
    "        zip_ref.extractall(image_path)"
   ],
   "id": "82a25a42a529a8f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")\n",
    "\n",
    "walk_through_dir(image_path)"
   ],
   "id": "fba0bed221e1c7f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "train_dir, test_dir"
   ],
   "id": "1dd823fcf79da9c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "random.seed(234)\n",
    "#image path\n",
    "image_path_list=list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "random_image_path=random.choice(image_path_list)\n",
    "image_class=random_image_path.parent.stem\n",
    "img=Image.open(random_image_path)\n",
    "print(random_image_path)\n",
    "print(image_class)\n",
    "img"
   ],
   "id": "b7aca63095a93a26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img_as_array=np.array(img)\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels]\")\n"
   ],
   "id": "52e457e3e81f3d33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "data_transform(img)"
   ],
   "id": "5a687a7e08fb30a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_transformed_image(image_paths, transform, n=3, seed=420):\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(f)\n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis('off')\n",
    "\n",
    "            transformed_image = transform(f).permute(1, 2, 0)\n",
    "            ax[1].imshow(transformed_image)\n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis('off')\n",
    "\n",
    "            fig.suptitle(f\"Image class: {image_path.parent.stem}\", fontsize=16)\n",
    "\n",
    "plot_transformed_image(image_path_list, transform=data_transform, n=3)"
   ],
   "id": "dc9d2715c51a03c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
    "                                  transform=data_transform, # transforms to perform on data (images)\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir,\n",
    "                                 transform=data_transform)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
   ],
   "id": "41bab2cdcf3f1a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_names = train_data.classes\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict, class_names\n"
   ],
   "id": "bb82a38ea93a42b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img, label = train_data[0][0], train_data[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ],
   "id": "56b09d429e29c20b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=1, # how many samples per batch?\n",
    "                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n",
    "                              shuffle=True) # shuffle the data?\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=1,\n",
    "                             num_workers=1,\n",
    "                             shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_dataloader, test_dataloader"
   ],
   "id": "4f86ce1f7b882b70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, List"
   ],
   "id": "4e6c52c87579634c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target_directory = train_dir\n",
    "print(f\"Target directory: {target_directory}\")\n",
    "\n",
    "class_names_found = sorted([entry.name for entry in list(os.scandir(image_path / \"train\"))])\n",
    "print(f\"Class names found: {class_names_found}\")"
   ],
   "id": "a520e21a329196ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "\n",
    "    # 1. Get the class names by scanning the target directory\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "\n",
    "    # 2. Raise an error if class names not found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "\n",
    "    # 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx\n",
    "find_classes(train_dir)"
   ],
   "id": "4f70b6162d9ffe56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a custom Dataset to replicate ImageFolder",
   "id": "86029423fedf3de6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ImageFolderCustom(Dataset):\n",
    "    def __init__(self, target_dir: str, transform=None):\n",
    "        self.paths = list(pathlib.Path(target_dir).glob(\"*/*.jpg\"))\n",
    "        self.transform = transform\n",
    "        self.classes, self.class_to_idx = find_classes(target_dir)\n",
    "\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Open an image via a path and return it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of the data, data and label\"\n",
    "        img=self.load_image(index)\n",
    "        class_names=self.paths[index].parent.name\n",
    "        class_idx=self.class_to_idx[class_names]\n",
    "\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx\n",
    "        else:\n",
    "            return img, class_idx"
   ],
   "id": "e42e94d5b20bf19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Don't augment test data, only reshape\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ],
   "id": "10acf3723237cb73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_data_custom = ImageFolderCustom(target_dir=train_dir,\n",
    "                                      transform=train_transforms)\n",
    "test_data_custom = ImageFolderCustom(target_dir=test_dir,\n",
    "                                     transform=test_transforms)\n",
    "train_data_custom, test_data_custom"
   ],
   "id": "ce725aa0d79c137d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fb8d027386aadc21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "643684361caf9502",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5a996848e47475bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fe2881004e93269",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "55091db0776a7288",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c84d9cd250f65501",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "15e38639412e92bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9b055c680caa97e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "23b9b1d716b39d09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "22b582bbce9c1d28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cfbc868400a836a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8f6569fab8ffe03d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d88ea6cfbc77ac4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": "",
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
