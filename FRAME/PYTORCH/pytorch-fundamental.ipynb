{
 "cells": [
  {
   "cell_type": "code",
   "id": "bf1ee82e-9291-4e30-92fa-3269eb9dfe64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T05:20:26.418324Z",
     "start_time": "2025-03-31T05:20:23.149126Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"GPU is not available, using CPU.\")   "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n",
      "GPU Name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Total Memory: 6.44 GB\n",
      "CUDA Version: 12.6\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#https://pytorch.org/docs/stable/tensors.html\n",
    "#creating tensor\n",
    "#scalar\n",
    "scalar = torch.tensor(1)\n",
    "scalar"
   ],
   "id": "f4a2740917b919ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(scalar.item())\n",
    "scalar.item()"
   ],
   "id": "724ae3bf7fc5b289",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vector = torch.tensor([1, 3])\n",
    "vector"
   ],
   "id": "62fd1e78b462731e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "float_32_tensor = torch.tensor([3.0, 4.0, 5.0],\n",
    "                               dtype=torch.float32,\n",
    "                               device=\"cpu\",\n",
    "                               requires_grad=False)\n",
    "print(float_32_tensor.dtype)\n",
    "float_32_tensor\n"
   ],
   "id": "89a3ef391b315b9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ],
   "id": "c940cabcd311fb0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Manupilating Tensors",
   "id": "80e5fc005f0b646b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(tensor + 10)\n",
    "\n",
    "#multiply\n",
    "print(tensor * 10)\n",
    "print(torch.mul(tensor, 10))"
   ],
   "id": "252ddb73c43329a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Matrix multiplication\n",
    "\n",
    "#Element wise multiplication\n",
    "print(tensor, \"*\", tensor, \"=\", {tensor * tensor})\n",
    "\n",
    "#matrix multiplcation\n",
    "print(torch.matmul(tensor, tensor))\n"
   ],
   "id": "814207bffe90655",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T05:19:08.178840Z",
     "start_time": "2025-03-31T05:19:07.317433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "mil_cpu = torch.rand(10000, 10000)\n",
    "\n",
    "value_cpu = torch.sum(mil_cpu * mil_cpu)\n",
    "print(value_cpu)"
   ],
   "id": "72118d063e19b751",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33335852.)\n",
      "CPU times: total: 1.7 s\n",
      "Wall time: 832 ms\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T05:19:10.717647Z",
     "start_time": "2025-03-31T05:19:10.545525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "mil_gpu = torch.rand(10000, 10000, device=\"cuda\")\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "value_gpu = torch.sum(mil_gpu * mil_gpu)\n",
    "torch.cuda.synchronize()  # Ensure the computation is done\n",
    "print(value_gpu)\n"
   ],
   "id": "dc8920b0df82ea93",
   "outputs": [
    {
     "ename": "DeferredCudaCallError",
     "evalue": "CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n    app.start()\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 645, in run_forever\n    self._run_once()\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1999, in _run_once\n    handle._run()\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3047, in run_cell\n    result = self._run_cell(\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3102, in _run_cell\n    result = runner(coro)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n    coro.send(None)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3306, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3489, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3549, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\anmol\\AppData\\Local\\Temp\\ipykernel_8476\\458575396.py\", line 1, in <module>\n    import torch\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 2046, in <module>\n    _C._initExtension(_manager_path())\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 264, in <module>\n    _lazy_call(_check_capability)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 261, in _lazy_call\n    _queued_calls.append((callable, traceback.format_stack()))\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Artificial\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:330\u001B[39m, in \u001B[36m_lazy_init\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    329\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m330\u001B[39m     \u001B[43mqueued_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    331\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Artificial\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:197\u001B[39m, in \u001B[36m_check_capability\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    191\u001B[39m old_gpu_warn = \u001B[33m\"\"\"\u001B[39m\n\u001B[32m    192\u001B[39m \u001B[33mFound GPU\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m which is of cuda capability \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m.\u001B[39m\n\u001B[32m    193\u001B[39m \u001B[33mPyTorch no longer supports this GPU because it is too old.\u001B[39m\n\u001B[32m    194\u001B[39m \u001B[33mThe minimum cuda capability supported by this library is \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m.\u001B[39m\n\u001B[32m    195\u001B[39m \u001B[33m\u001B[39m\u001B[33m\"\"\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mversion\u001B[49m.cuda \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# on ROCm we don't want this check\u001B[39;00m\n\u001B[32m    198\u001B[39m     CUDA_VERSION = torch._C._cuda_getCompiledVersion()  \u001B[38;5;66;03m# noqa: F841\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Artificial\\.venv\\Lib\\site-packages\\torch\\__init__.py:2681\u001B[39m, in \u001B[36m__getattr__\u001B[39m\u001B[34m(name)\u001B[39m\n\u001B[32m   2679\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib.import_module(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m, \u001B[34m__name__\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m2681\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mmodule \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m has no attribute \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mAttributeError\u001B[39m: module 'torch' has no attribute 'version'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mDeferredCudaCallError\u001B[39m                     Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m<timed exec>:1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Artificial\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:336\u001B[39m, in \u001B[36m_lazy_init\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    331\u001B[39m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    332\u001B[39m             msg = (\n\u001B[32m    333\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCUDA call failed lazily at initialization with error: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    334\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCUDA call was originally invoked at:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m'\u001B[39m.join(orig_traceback)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    335\u001B[39m             )\n\u001B[32m--> \u001B[39m\u001B[32m336\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m DeferredCudaCallError(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m    337\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    338\u001B[39m     \u001B[38;5;28mdelattr\u001B[39m(_tls, \u001B[33m\"\u001B[39m\u001B[33mis_initializing\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mDeferredCudaCallError\u001B[39m: CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n    app.start()\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 645, in run_forever\n    self._run_once()\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1999, in _run_once\n    handle._run()\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3047, in run_cell\n    result = self._run_cell(\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3102, in _run_cell\n    result = runner(coro)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n    coro.send(None)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3306, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3489, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3549, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\anmol\\AppData\\Local\\Temp\\ipykernel_8476\\458575396.py\", line 1, in <module>\n    import torch\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 2046, in <module>\n    _C._initExtension(_manager_path())\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 264, in <module>\n    _lazy_call(_check_capability)\n  File \"D:\\Artificial\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 261, in _lazy_call\n    _queued_calls.append((callable, traceback.format_stack()))\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "x = torch.arange(6).reshape(2, 3)\n",
    "print(\"Original Tensor:\\n\", x)\n",
    "\n",
    "# View as a different shape\n",
    "y = x.view(3, 2)\n",
    "print(\"Viewed Tensor:\\n\", y)\n",
    "\n",
    "# Modifying the viewed tensor affects the original\n",
    "y[0, 0] = 999\n",
    "print(\"Modified View Tensor:\\n\", y)\n",
    "print(\"Original Tensor After Modification:\\n\", x)\n"
   ],
   "id": "4386f50b36eaf47c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.arange(6).reshape(2, 3)\n",
    "z = x.T  # Transpose makes it non-contiguous\n",
    "\n",
    "# Reshape works without needing .contiguous()\n",
    "reshaped_z = z.reshape(3, 2)\n",
    "print(\"Reshaped Tensor:\\n\", reshaped_z)\n",
    "\n",
    "x_stack=torch.stack([x,x], dim=1)\n",
    "x_stack"
   ],
   "id": "36479799d171b6d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T17:26:21.741028Z",
     "start_time": "2025-02-26T17:26:21.735814Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.device_count()",
   "id": "a1abd942068eae47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
