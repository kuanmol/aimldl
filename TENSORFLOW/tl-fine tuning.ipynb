{
 "cells": [
  {
   "cell_type": "code",
   "id": "5cc0bd8dfddb438d",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from keras_preprocessing import image\n",
    "\n",
    "train_dir = '10_food_classes_10_percent/train'\n",
    "test_dir = '10_food_classes_10_percent/test'\n",
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 32\n",
    "train_data_10_percent=tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
    "                                                                           image_size=IMG_SIZE,\n",
    "                                                                          label_mode=\"categorical\",\n",
    "                                                                          batch_size=BATCH_SIZE)\n",
    "test_data=tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                              image_size=IMG_SIZE,\n",
    "                                                              label_mode=\"categorical\",\n",
    "                                                              batch_size=BATCH_SIZE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MODEL 0 transfer learning model using functional api\n",
   "id": "ab9375be1b49f944"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.api.applications import EfficientNetB0\n",
    "from keras.api.layers import Flatten, Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from keras.api.models import Model\n",
    "from TENSORFLOW.helper_functions import create_tensorboard_callback, plot_loss_curves\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.api.losses import categorical_crossentropy\n",
    "\n",
    "#create base model\n",
    "base_model = EfficientNetB0(include_top=False)\n",
    "\n",
    "#freeze base model\n",
    "base_model.trainable = False\n",
    "\n",
    "#create input into our model\n",
    "inputs = Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "\n",
    "#pass the input to the base model\n",
    "x = base_model(inputs)\n",
    "print(f\"Shape after passing input through the base model: {x.shape}\")\n",
    "\n",
    "x = GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "\n",
    "print(f\"Shape after global average pooling layer: {x.shape}\")\n",
    "\n",
    "outputs = Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "model_0 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_0.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "history_10 = model_0.fit(train_data_10_percent, epochs=5,\n",
    "                         steps_per_epoch=len(train_data_10_percent),\n",
    "                         validation_data=test_data,\n",
    "                         validation_steps=int(0.25 * len(test_data)),\n",
    "                         callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",\n",
    "                                                                experiment_name=\"10%_feature_extraction\")], verbose=2)"
   ],
   "id": "190db08aeffd2302",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_0.evaluate(test_data)",
   "id": "1a878f55105e2e18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for layer_number, layer in enumerate(base_model.layers):\n",
    "    print(layer_number,layer.name)"
   ],
   "id": "1724b0e9802a5d94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_0.summary()",
   "id": "9654fb3890ef649b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from TENSORFLOW.helper_functions import plot_loss_curves, pred_and_plot, compare_historys,confusion_matrix\n",
    "\n",
    "plot_loss_curves(history_10)"
   ],
   "id": "30e4b193a69c8f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "!curl -O https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n",
    "\n",
    "zip_ref=zipfile.ZipFile('10_food_classes_1_percent.zip')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()\n",
    "\n",
    "train_dir_1_percent = \"10_food_classes_1_percent/train/\"\n",
    "test_dir = \"10_food_classes_1_percent/test/\""
   ],
   "id": "39a34a8b20a530c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "IMG_SIZE = (224, 224)\n",
    "train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_1_percent,\n",
    "                                                                           label_mode=\"categorical\",\n",
    "                                                                           batch_size=32, # default\n",
    "                                                                           image_size=IMG_SIZE)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                image_size=IMG_SIZE)"
   ],
   "id": "d5e667a028bb40a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Data augmentation pipeline\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomHeight(0.2),\n",
    "    layers.RandomWidth(0.2),\n",
    "    # layers.Rescaling(1./255)  # Uncomment for ResNet50V2, remove for EfficientNetV2B0\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "print(\"Data augmentation layer created successfully!\")\n"
   ],
   "id": "eb0904e361308694",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import random\n",
    "\n",
    "target_class = random.choice(train_data_1_percent.class_names)  # choose a random class\n",
    "target_dir = \"10_food_classes_1_percent/train/\" + target_class  # create the target directory\n",
    "random_image = random.choice(os.listdir(target_dir))  # choose a random image from target directory\n",
    "random_image_path = target_dir + \"/\" + random_image  # create the choosen random image path\n",
    "img = mpimg.imread(random_image_path)  # read in the chosen target image\n",
    "plt.imshow(img)  # plot the target image\n",
    "plt.title(f\"Original random image from class: {target_class}\")\n",
    "plt.axis(False);  # turn off the axes\n",
    "\n",
    "# Augment the image\n",
    "augmented_img = data_augmentation(tf.expand_dims(img, axis=0))\n",
    "# data augmentation model requires shape (None, height, width, 3)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(tf.squeeze(augmented_img) / 255.)  # requires normalization after augmentation\n",
    "plt.title(f\"Augmented random image from class: {target_class}\")\n",
    "plt.axis(False);"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
